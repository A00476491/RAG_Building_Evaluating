{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated evaluation Pipeline\n",
    "\n",
    "### What Needs to Be Automated?\n",
    "- Generate questions\n",
    "- Check retrieval Performance\n",
    "- Detect model hallucinations\n",
    "\n",
    "### Pipeline\n",
    "\n",
    "1. **Generate Questions:**  \n",
    "   - Provide 100 case articles to ChatGPT and let it generate a question for each case article. \n",
    "   - Get (case article, question)\n",
    "\n",
    "2. **Generate Answers:**  \n",
    "   - Use our RAG model to answer the generated questions.\n",
    "   - Get (case article, question, answer, retrieved articles)\n",
    "\n",
    "3. **Evaluate Retrieval Performance:**  \n",
    "   - Check if each case article is in the retrieved articles using:\n",
    "     - Accuracy@3\n",
    "     - Accuracy@2\n",
    "     - Accuracy@1\n",
    "   - Get (case article, question, answer, retrieved articles, Retrieval status)\n",
    "\n",
    "4. **Detect Hallucination:**  \n",
    "   - Provide the answer and retrieved articles to ChatGPT.  \n",
    "   - Let ChatGPT determine if hallucinations occured and provide a reason.\n",
    "   - Get (case article, answer, retrieved articles, Retrieval status, hallucinated, reason)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ml\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "from components.rag import query_answering_system\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate questions by Chatgpt\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def generate_question(article):\n",
    "    prompt = (\n",
    "        \"Generate a simple, easy-to-understand and not too long question based on the following news content.\"\n",
    "        \"Also, the question must be specific and clear. For example, instead of using 'servants,' it should specify which region or countryâ€™s servants are being referred to.\"\n",
    "        \"Additionally, the question should not be too difficult, and the answer must be explicitly contained within the following News content.\\n\\n\"\n",
    "        f\"News content:\\n{article}\\n\\n\"\n",
    "        \"Question:\"\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "df_1K = pd.read_csv('../data/1K_news.csv', encoding='utf-8')\n",
    "\n",
    "# Select the first 100 rows\n",
    "df = df_1K.head(100)\n",
    "\n",
    "# Apply the function to generate questions\n",
    "df[\"generated_question\"] = df[\"text\"].apply(generate_question)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "# df.to_csv(\"./100_news_questions.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Question generation completed. Results saved to news_questions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Case Article**\n",
    "\n",
    "Bitcoin dropped to its lowest level in 3.5 months on Friday, dragged by uncertainty about U.S. President Donald Trump's tariff plans, crypto policy, and flagging investor confidence after a $1.5 billion hack in rival cryptocurrency Ether.\n",
    "\n",
    "Bitcoin, the world's largest cryptocurrency by market value, was last down more than 5% on the day at **$79,666**, trading below $80,000 for the first time since November 11.\n",
    "\n",
    "### **GPT-generated Question**\n",
    "What was the price of Bitcoin when it dropped to its lowest level in 3.5 months on Friday?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate answers by Rag\n",
    "df = pd.read_csv('./100_news_questions.csv', encoding='utf-8')\n",
    "document_dataset = \"../data/1K_news.csv\"\n",
    "for i in range(len(df)):\n",
    "    query = df.loc[i, 'generated_question']\n",
    "    output = query_answering_system(query, document_dataset)\n",
    "    df.loc[i, 'generated_response'] = output['answer']\n",
    "    df.loc[i, 'retrieved_docs_id'] = str(output['retrieved_docs_id'])[1:-1]\n",
    "\n",
    "    print(f\"Processing question ({i+1}/{len(df)}) and response generated.\")\n",
    "\n",
    "df.to_csv(\"./100_news_QA.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-generated Question  \n",
    "\n",
    "What was the price of Bitcoin when it dropped to its lowest level in 3.5 months on Friday?\n",
    "\n",
    "### Rag-generated Answer  \n",
    "\n",
    "Bitcoin, the world's largest cryptocurrency by market value, was last down more than 5% on the day at **$79,666**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Performance Metrics:\n",
      "--------------------------------\n",
      "Top-1 Accuracy: 0.8500 - The proportion of cases where the case article is ranked first.\n",
      "Top-2 Accuracy: 0.9400 - The proportion of cases where the case article is in the top 2 results.\n",
      "Top-3 Accuracy: 0.9500 - The proportion of cases where the case article is in the top 3 results.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate retrieval performance using Accuracy metrics\n",
    "\n",
    "df = pd.read_csv('./100_news_QA.csv', encoding='utf-8')\n",
    "TP_3 = 0\n",
    "TP_2 = 0\n",
    "TP_1 = 0\n",
    "for i in range(len(df)):\n",
    "\n",
    "    content_id = str(df['content_id'][i])\n",
    "    retrieved_docs_id = df['retrieved_docs_id'][i].split(', ')\n",
    "\n",
    "    if content_id == retrieved_docs_id[0]:\n",
    "        TP_1 += 1\n",
    "        TP_2 += 1\n",
    "        TP_3 += 1\n",
    "    elif content_id == retrieved_docs_id[1]:\n",
    "        TP_2 += 1\n",
    "        TP_3 += 1\n",
    "    elif content_id == retrieved_docs_id[2]:\n",
    "        TP_3 += 1\n",
    "\n",
    "Accuracy_top3 = TP_3 / len(df)\n",
    "Accuracy_top2 = TP_2 / len(df)\n",
    "Accuracy_top1 = TP_1 / len(df)\n",
    "\n",
    "print(f\"Retrieval Performance Metrics:\")\n",
    "print(f\"--------------------------------\")\n",
    "print(f\"Top-1 Accuracy: {Accuracy_top1:.4f} - The proportion of cases where the case article is ranked first.\")\n",
    "print(f\"Top-2 Accuracy: {Accuracy_top2:.4f} - The proportion of cases where the case article is in the top 2 results.\")\n",
    "print(f\"Top-3 Accuracy: {Accuracy_top3:.4f} - The proportion of cases where the case article is in the top 3 results.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Chat GPT evaluate if Rag has model hallucination\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def evaluate_rag_hallucinated(retrieved_articles, answer):\n",
    "    prompt = (\n",
    "        \"Evaluate whether the Knowledge-based AI assistant's state is factually accurate based only on the given documents.\\n\"\n",
    "        \"Your response should be in two rows:\\n\"\n",
    "        \"1. First row: True or False (True if the answer is fully supported by the documents, False if it contains hallucinated or unverifiable information).\\n\"\n",
    "        \"2. Second row: A short explanation for your decision.\\n\\n\"\n",
    "        \"Documents:\\n\"\n",
    "        f\"{retrieved_articles}\\n\\n\"\n",
    "        \"Answer from the AI assistant:\\n\"\n",
    "        f\"{answer}\\n\\n\"\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "df = pd.read_csv('./100_news_QA.csv', encoding='utf-8')\n",
    "df_1K = pd.read_csv('../data/1K_news.csv', encoding='utf-8')\n",
    "\n",
    "df[\"hallucinated\"] = None\n",
    "df[\"reason\"] = None\n",
    "\n",
    "for i in range(len(df)):\n",
    "\n",
    "    doc_ids = list(map(int, df[\"retrieved_docs_id\"][i].split(\", \")))\n",
    "    retrieved_articles = df_1K[df_1K['content_id'].isin(doc_ids)]['text']\n",
    "    retrieved_articles = \"\\n\\n\".join([f\"document{j+1}: {retrieved_articles.iloc[j]}\" for j in range(min(3, len(retrieved_articles)))])\n",
    "        \n",
    "    isHallucinated, reason = evaluate_rag_hallucinated(retrieved_articles, df.loc[i, \"generated_response\"]).splitlines()\n",
    "    df.loc[i, 'hallucinated'] = isHallucinated\n",
    "    df.loc[i, 'reason'] = reason\n",
    "\n",
    "df.to_csv(\"./100_news_QA_hallucination.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hallucination rate:** **40%**\n",
    "\n",
    "### Answer\n",
    "Apollo Global Management is discussing **a $305 million funding** round to help Meta Platforms develop data centers in the U.S.\n",
    "\n",
    "### Why Hallucinated\n",
    "Incorrectly states the financing amount as *$305 million*, while the documents indicate that Apollo Global Management is in talks for a financing package of roughly **$35 billion** for Meta Platforms.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
